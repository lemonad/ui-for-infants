---
title:   "Background III: Pursuit for infants?"
date:    2018-05-25 22:05:21
excerpt: "Smooth pursuits in infants reaches adult performance in just five months."

---
Neonates (children less than four weeks old) can sometimes track objects
if they are large and move slowly. At this age they seem to rely on saccades
(rapid jumps between different fixation points in the same direction, usually
occuring several times per second).

From about six weeks, a different eye movement, smooth pursuits, improves
and infants begin to track things moving in a smooth pattern. At about
five months, smooth pursuits reaches adult performance when it comes to
sinusoidally and horizontally moving targets.

To explore the uncharted territory of UIs for infants, Pursuits seem to be a
particularly good match, especially if limited to smooth horizontal movement
patterns.

For me, there are a few particularly interesting aspects here. First; if we
want to know if it is possible for infants to learn to use applications
equipped with gaze interaction, what kind of interfaces do we construct in
order to try to find that out?

Second; what if we could get these gaze-driven applications in the hands of
(millions of) parents through tablets, mobiles and the web? It is here that I
think Pursuits could be extremely useful. The built-in video capabilites of
most devices today should be good enough to identify gaze-following (at least
with exaggerated motions), and since there is no calibration step to go through
(which is difficult when it comes to infants), the big technical obstacles
may very well be out of the way.

The thing is that it would really only take a few children to provide a
starting point for iterative improvements. Once we know it is possible,
we have a sort of baseline from which we can start exploring the design
of these user interfaces.

Third; if successful, what do we do with that knowledge? What interesting
research questions could we then hope to answer? What interesting applications
will be developed?

 As infant motor skills develop considerably later than their vision,
there should be a window for gaze-only interaction design of *at least*
six months.
